{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52832fd4",
   "metadata": {},
   "source": [
    "# Funciones Útiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a445e7c3",
   "metadata": {},
   "source": [
    "Este archivo contiene funciones útiles para el proceso de Extracción, Transformación y Carga (ETL)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84371c3",
   "metadata": {},
   "source": [
    "## Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec208b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188fc73",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19c3b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos_desde_excel(archivo, hojas, engine='openpyxl'):\n",
    "    \"\"\"\n",
    "    Carga datos desde un archivo Excel y devuelve un diccionario de DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - archivo (str): Ruta del archivo Excel.\n",
    "    - hojas (list): Lista de nombres de hojas a cargar.\n",
    "    - engine (str, optional): Motor de Excel a utilizar. Por defecto, 'openpyxl'.\n",
    "\n",
    "    Returns:\n",
    "    dfs: Un diccionario donde las claves son los nombres de las hojas y los valores son DataFrames correspondientes.\n",
    "\n",
    "    Example:\n",
    "    >>> datos = cargar_datos_desde_excel('archivo.xlsx', ['Hoja1', 'Hoja2'])\n",
    "    >>> df_hoja1 = datos['Hoja1']\n",
    "    >>> df_hoja2 = datos['Hoja2']\n",
    "    \"\"\"\n",
    "    \n",
    "    xls_file = pd.ExcelFile(archivo, engine=engine)\n",
    "    dfs = {}\n",
    "\n",
    "    for hoja in hojas:\n",
    "        df = pd.read_excel(xls_file, hoja) \n",
    "        dfs[hoja] = df\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c209407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_valores_sd(dataframe):\n",
    "    \"\"\"\n",
    "    Analiza la presencia de valores 'SD' en cada columna del DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): El DataFrame a analizar.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Un DataFrame que muestra la cantidad y porcentaje de valores 'SD' en cada columna.\n",
    "    \"\"\"\n",
    "    columnas_con_sd = dataframe.columns\n",
    "    resultados = []\n",
    "\n",
    "    for columna in columnas_con_sd:\n",
    "        cantidad_sd = dataframe[columna].eq('SD').sum()\n",
    "        porcentaje_sd = (cantidad_sd / len(dataframe)) * 100\n",
    "        resultados.append({'Columna': columna, 'Cantidad de SD': cantidad_sd, 'Porcentaje de SD': porcentaje_sd})\n",
    "\n",
    "    resultados_df = pd.DataFrame(resultados)\n",
    "    resultados_con_sd = resultados_df[resultados_df['Cantidad de SD'] > 0]\n",
    "\n",
    "    return resultados_con_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a955d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df, drop_duplicates=False, drop_na=False, fill_na=None, convert_to_datetime=None, uppercase_columns=None,\n",
    "                  lowercase_columns=None, titlecase_columns=None, strip_spaces=True, rename_columns=None, drop_columns=None,\n",
    "                  categorize_columns=None, replace_values=None, new_columns=None, convert_date_columns=None, \n",
    "                  convert_to_int_columns=None, convert_to_float=None, new_columns2=None):\n",
    "    \"\"\"\n",
    "    Realiza el proceso de limpieza de datos en un DataFrame.\n",
    "\n",
    "    Parámetros:\n",
    "    - df (pd.DataFrame): El DataFrame que se va a limpiar.\n",
    "    \n",
    "    - drop_duplicates (bool): Elimina duplicados si es True.\n",
    "      Ejemplo: cleaned_df = data_cleaning(df_tu_data_frame, drop_duplicates=True)\n",
    "    \n",
    "    - drop_na (bool): Elimina filas con valores nulos si es True.\n",
    "      Ejemplo: cleaned_df = data_cleaning(df_tu_data_frame, drop_na=True)\n",
    "\n",
    "    - fill_na (dict): Un diccionario donde las claves son los nombres de columnas y los valores son valores para rellenar los nulos.\n",
    "      Ejemplo: fill_na_dict = {'gravedad': 'leve'}\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, fill_na=fill_na_dict)\n",
    "        \n",
    "    - convert_to_datetime (list): Lista de columnas para convertir a tipo de dato datetime.\n",
    "      Ejemplo: columns_to_convert = ['fecha', 'hora']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, convert_to_datetime=columns_to_convert)\n",
    "\n",
    "    - uppercase_columns (list): Lista de columnas para convertir a mayúsculas.\n",
    "      Ejemplo: columns_to_uppercase = ['nombre', 'apellido']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, uppercase_columns=columns_to_uppercase)\n",
    "\n",
    "    - lowercase_columns (list): Lista de columnas para convertir a minúsculas.\n",
    "      Ejemplo: columns_to_lowercase = ['Ciudad', 'Pais']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, lowercase_columns=columns_to_lowercase)\n",
    "\n",
    "    - titlecase_columns (list): Lista de columnas para convertir a formato de título (primera letra en mayúscula, resto en minúscula).\n",
    "      Ejemplo: columns_to_titlecase = ['titulo', 'categoria']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, titlecase_columns=columns_to_titlecase)\n",
    "            \n",
    "    - strip_spaces (bool): Elimina espacios en blanco alrededor de los valores de las celdas si es True.\n",
    "      Ejemplo: cleaned_df = data_cleaning(df_tu_data_frame, strip_spaces=True)\n",
    "\n",
    "    - rename_columns (dict): Un diccionario donde las claves son los nombres de las columnas actuales y los valores son los nuevos nombres.\n",
    "      Ejemplo: rename_dict = {'Vieja_Columna': 'Nueva_Columna'}\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, rename_columns=rename_dict)\n",
    "    \n",
    "    - drop_columns (list): Lista de columnas para eliminar.\n",
    "      Ejemplo: columns_to_drop = ['columna1', 'columna2']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, drop_columns=columns_to_drop)\n",
    "        \n",
    "    - categorize_columns (list): Lista de columnas para convertir a tipo de dato categoría.\n",
    "      Ejemplo: columns_to_categorize = ['categoria1', 'categoria2']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, categorize_columns=columns_to_categorize)\n",
    "        \n",
    "    - replace_values (dict): Un diccionario donde las claves son los nombres de las columnas y los valores son diccionarios de reemplazo.\n",
    "      Ejemplo: replace_dict = {'columna1': {'Antiguo1': 'Nuevo1', 'Antiguo2': 'Nuevo2'}}\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, replace_values=replace_dict)\n",
    "\n",
    "    - new_columns (dict): Un diccionario donde las claves son los nombres de las nuevas columnas y los valores son valores para esas columnas.\n",
    "      Ejemplo: new_columns_dict = {'nueva_columna': 0}\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, new_columns=new_columns_dict)\n",
    "               \n",
    "    - new_columns2 (dict): Un diccionario donde las claves son los nombres de las nuevas columnas y los valores son expresiones\n",
    "                          para calcular el contenido de las nuevas columnas basadas en otras columnas existentes. \n",
    "      Ejemplo: {'nueva_columna1': 'columna_existente * 2'}\n",
    "      cleaned_df = data_cleaning(df_tu_data_frame, new_columns2=new_columns_dict)\n",
    "\n",
    " \n",
    "    - convert_date_columns (dict): Un diccionario donde las claves son los nombres de las columnas y los valores son los formatos de fecha.\n",
    "      Ejemplo: date_columns_dict = {'fecha': '%Y-%m-%d', 'hora': '%H:%M:%S'}\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, convert_date_columns=date_columns_dict)\n",
    "\n",
    "    - convert_to_int_columns (list): Lista de columnas para convertir a tipo de dato entero.\n",
    "      Ejemplo: columns_to_int = ['columna1', 'columna2']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, convert_to_int_columns=columns_to_int)\n",
    "    \n",
    "    - convert_to_float (list): Lista de columnas para convertir a tipo de dato float.\n",
    "      Ejemplo: columns_to_float = ['columna1', 'columna2']\n",
    "               cleaned_df = data_cleaning(df_tu_data_frame, convert_to_float=columns_to_float)          \n",
    "            \n",
    "    Retorna:\n",
    "    pd.DataFrame: El DataFrame limpio.\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_df = df.copy()\n",
    "\n",
    "    # Eliminar duplicados\n",
    "    if drop_duplicates:\n",
    "        cleaned_df.drop_duplicates(inplace=True)\n",
    "        \n",
    "\n",
    "    # Eliminar filas con valores nulos\n",
    "    if drop_na:\n",
    "        cleaned_df.dropna(inplace=True)\n",
    "        \n",
    "\n",
    "    # Rellenar valores nulos\n",
    "    if fill_na:\n",
    "        cleaned_df.fillna(fill_na, inplace=True)\n",
    "\n",
    "        \n",
    "    # Convertir columnas a tipo datetime\n",
    "    if convert_to_datetime:\n",
    "        for column in convert_to_datetime:\n",
    "            cleaned_df[column] = pd.to_datetime(cleaned_df[column], errors='coerce')\n",
    "            \n",
    "\n",
    "    # Convertir columnas a mayúsculas\n",
    "    if uppercase_columns:\n",
    "        for column in uppercase_columns:\n",
    "            cleaned_df[column] = cleaned_df[column].str.upper()\n",
    "            \n",
    "\n",
    "    # Convertir columnas a minúsculas\n",
    "    if lowercase_columns:\n",
    "        for column in lowercase_columns:\n",
    "            cleaned_df[column] = cleaned_df[column].str.lower()\n",
    "        \n",
    "\n",
    "    # Convertir columnas a formato de título\n",
    "    if titlecase_columns:\n",
    "        for column in titlecase_columns:\n",
    "            cleaned_df[column] = cleaned_df[column].str.title()\n",
    "            \n",
    "            \n",
    "    # Tratar columnas con espacios\n",
    "    if strip_spaces:\n",
    "        cleaned_df = cleaned_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "        \n",
    "\n",
    "    # Renombrar columnas\n",
    "    if rename_columns:\n",
    "        cleaned_df.rename(columns=rename_columns, inplace=True)\n",
    "        \n",
    "    \n",
    "    # Eliminar columnas\n",
    "    if drop_columns:\n",
    "        cleaned_df.drop(columns=drop_columns, inplace=True)\n",
    "        \n",
    "        \n",
    "    # Categorizar columnas\n",
    "    if categorize_columns:\n",
    "        for column in categorize_columns:\n",
    "            if column in cleaned_df.columns:\n",
    "                cleaned_df[column] = cleaned_df[column].astype('category')\n",
    "            else:\n",
    "                print(f\"La columna '{column}' no existe en el DataFrame.\")\n",
    "                \n",
    "\n",
    "    # Reemplazar valores en columnas\n",
    "    if replace_values:\n",
    "        for column, replacements in replace_values.items():\n",
    "            cleaned_df[column].replace(replacements, inplace=True)\n",
    "            \n",
    "    # Agregar nuevas columnas\n",
    "    if new_columns:\n",
    "        for column, value in new_columns.items():\n",
    "            cleaned_df[column] = value\n",
    "            \n",
    "    # Agregar nuevas columnas basadas en otras columnas\n",
    "    if new_columns2:\n",
    "        for new_column, column_expr in new_columns2.items():\n",
    "            # Verificar si la expresión es proporcionada\n",
    "            if column_expr:\n",
    "                cleaned_df[new_column] = cleaned_df.eval(column_expr)\n",
    "            else:\n",
    "                cleaned_df[new_column] = None  # O cualquier valor predeterminado que prefieras\n",
    "                  \n",
    "    # Convertir columnas de fecha con formato específico\n",
    "    if convert_date_columns:\n",
    "        for column, date_format in convert_date_columns.items():\n",
    "            cleaned_df[column] = pd.to_datetime(cleaned_df[column], format=date_format, errors='coerce')\n",
    "\n",
    "    \n",
    "    # Convertir columnas a tipo de dato entero\n",
    "    if convert_to_int_columns:\n",
    "        for column in convert_to_int_columns:\n",
    "            cleaned_df[column] = pd.to_numeric(cleaned_df[column], errors='coerce').astype('Int64')\n",
    "    \n",
    "    \n",
    "    # Convertir columnas a tipo float\n",
    "    if convert_to_float:\n",
    "        for column in convert_to_float:\n",
    "            cleaned_df[column] = cleaned_df[column].astype(float)\n",
    "        \n",
    "            \n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97cbf2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mysql_db(csv_file_path, db_name, table_name, host='localhost', user='tu_usuario', password='tu_contraseña'):\n",
    "    \"\"\"\n",
    "    Crea una base de datos MySQL y una tabla a partir de un archivo CSV.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_file_path (str): Ruta del archivo CSV.\n",
    "    - db_name (str): Nombre de la base de datos a crear.\n",
    "    - table_name (str): Nombre de la tabla a crear.\n",
    "    - host (str, optional): Dirección del servidor MySQL. Por defecto, 'localhost'.\n",
    "    - user (str, optional): Usuario de MySQL. Por defecto, 'tu_usuario'.\n",
    "    - password (str, optional): Contraseña de MySQL. Por defecto, 'tu_contraseña'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validaciones\n",
    "        if not csv_file_path.endswith('.csv'):\n",
    "            raise ValueError(\"El archivo debe tener extensión CSV.\")\n",
    "\n",
    "        # Cargar CSV en un DataFrame\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        # Conectar a MySQL y crear la base de datos si no existe\n",
    "        connection = mysql.connector.connect(\n",
    "            host=host,\n",
    "            user=user,\n",
    "            password=password\n",
    "        )\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "        # Conectar a MySQL y crear la tabla si no existe\n",
    "        engine = create_engine(f'mysql+mysqlconnector://{user}:{password}@{host}:3306/{db_name}')\n",
    "        connection = engine.connect()\n",
    "        df.to_sql(table_name, connection, index=False, if_exists='replace')\n",
    "        connection.close()\n",
    "\n",
    "        print(\"Base de datos y tabla creadas exitosamente.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        raise ValueError(\"El archivo CSV está vacío.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error al conectar a MySQL: {err}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65817dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
